{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0dc7441-1e92-4e8c-a7ed-973647024d5c",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e520d9f-a74d-48e2-8d7a-2086d6d7edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645682a5-fb39-4f05-a91e-c6522921e757",
   "metadata": {},
   "source": [
    "### Loading Images and Class Names for Attendance Recognition\n",
    "In this part of the code, a loop iterates through the list of files obtained from the 'myList' variable, representing the image files in the 'images_Attendance' directory. For each file (image), it reads the image using OpenCV's 'cv2.imread()' function, appends the image to the 'images' list, and extracts the class name from the file name using 'os.path.splitext(cls)[0]'. The class name is then added to the 'classNames' list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81d4613b-d181-4b92-a93b-3c0e7822bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill gates.jpg', 'cristiano ronaldo.jpg', 'elon musk.jpg', 'leo messi.jpg', 'Leonardo DiCaprio.jpg', 'Mohammad Al Smadi.jpg', 'Robert DeNiro.jpg']\n"
     ]
    }
   ],
   "source": [
    "path = 'images_Attendance'\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49000e4c-7a24-4447-bf4b-cee17e5b04b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill gates', 'cristiano ronaldo', 'elon musk', 'leo messi', 'Leonardo DiCaprio', 'Mohammad Al Smadi', 'Robert DeNiro']\n"
     ]
    }
   ],
   "source": [
    "for cls in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cls}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cls)[0])\n",
    "\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec32343-5b30-4f5f-92a7-2b337c221be8",
   "metadata": {},
   "source": [
    "### Encoding Faces for Attendance Recognition\n",
    "In this section of the code, a function called 'findEncodings' is defined to encode facial features from a list of images. The function takes a list of images as input and iterates through each image. For each image, it first converts the image from BGR format to RGB format using OpenCV's 'cv2.cvtColor()' function. Then, it uses the 'face_recognition.face_encodings()' function to extract facial encodings, and the first (and usually only) encoding is appended to the 'encodeList'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96bfd82f-480c-4ed3-b556-8ce7c5fcdedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding complete\n"
     ]
    }
   ],
   "source": [
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "lstEncode = findEncodings(images)\n",
    "print('Encoding complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7944b05-4a8a-40b5-96d7-7a6d6d5d6d46",
   "metadata": {},
   "source": [
    "### Marking Attendance in CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d82e8fa-6adf-476e-9b3c-ef63618cd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open('Attendance.csv','r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "            if name not in nameList:\n",
    "                now = datetime.now()\n",
    "                dtString = now.strftime('%H:%M:%S')\n",
    "                f.writelines(f'n{name},{dtString}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ca39e-55f6-4920-a339-d3323d29b451",
   "metadata": {},
   "source": [
    "### Real-time Face Recognition and Attendance Marking\n",
    "In this code, a real-time face recognition and attendance marking system is implemented using OpenCV and the face_recognition library. The code captures video from the default camera (0) and continuously processes frames to detect and recognize faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a61160de-66a7-48bd-9373-2e726b8561db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n",
      "Mohammad al smadi\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    sucess, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0,0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "    \n",
    "    for encodeFace, faceLoc in zip(encodeCurFrame, facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(lstEncode, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(lstEncode, encodeFace)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].capitalize()\n",
    "            print(name)\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1*4, x2*4, y2*4, x1*4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1, y2-35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1+6, y2-6), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 2)\n",
    "            markAttendance(name)\n",
    "\n",
    "    cv2.imshow('WebCam', img)\n",
    "    if cv2.waitKey(1) != -1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
